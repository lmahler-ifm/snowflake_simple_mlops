{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "uvk2kb5xt2wgvygvxf6p",
   "authorId": "5384571919373",
   "authorName": "ADMIN",
   "authorEmail": "michael.gorkow@snowflake.com",
   "sessionId": "efb500bb-87d9-4bb0-8af3-2a2db82ae4c4",
   "lastEditTime": 1741471883291
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e090cc90-29da-47e1-bd9b-2f7ac5eedad5",
   "metadata": {
    "collapsed": false,
    "name": "SETUP_0"
   },
   "source": [
    "# Use Case: Predicting Future Customer Revenue Using Historical Transaction Data ðŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59214b-4111-4c5d-8a06-1e9f091a4620",
   "metadata": {
    "collapsed": false,
    "name": "SETUP_1"
   },
   "source": [
    "# 1 - Setup Demo ðŸ› ï¸\n",
    "* Import required libraries\n",
    "* Create a Snowpark session\n",
    "\n",
    "| Library    | Use |\n",
    "| -------- | ------- |\n",
    "| `snowflake.snowpark` | Main Python Developer Framework for Snowflake including the DataFrame-API     |\n",
    "| `snowflake.ml`    | Snowflake ML specific functions including Feature Store & Model Registry APIs    |\n",
    "| `snowflake.cortex`    | Snowflake APIs to access Cortex Services (e.g. LLMs)    |\n",
    "| `notebook_extras`  | Convenience Functions for Snowflake Notebooks. More details [here](google.com).    |\n",
    "| `demo_extras`  | Demo-specific functions (Data Generation, Use Case flow, etc.)     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fbb66-2845-488b-9878-1a90da9edc53",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "SETUP_2"
   },
   "outputs": [],
   "source": "# Helper functions for this demo\nfrom demo_extras.flow import Demoflow\nfrom notebook_extras.cortex import CortexPilot\nfrom notebook_extras.model_registry import ModelRegistryHelper\nfrom notebook_extras.lineage import LineageHelper\nfrom notebook_extras.misc import get_snowsight_url\n\n\n# Import python packages\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport streamlit as st\nfrom streamlit import dataframe as sdf\nimport pandas as pd\nimport numpy as np\nimport shap\nimport warnings\nimport logging\nfrom opentelemetry import trace\nfrom snowflake import telemetry\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\n# Import Snowflake packages\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import functions as F\nfrom snowflake.snowpark.functions import lit, col, sproc\nfrom snowflake.ml.modeling.xgboost import XGBRegressor\nfrom snowflake.ml.modeling.metrics import mean_absolute_percentage_error\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.monitoring.entities.model_monitor_config import ModelMonitorSourceConfig, ModelMonitorConfig\nfrom snowflake.ml.feature_store import (\n    FeatureStore,\n    FeatureView,\n    Entity,\n    CreationMode\n)\n\ndemo_flow = Demoflow()\ndemo_flow.setup()\n\nsession = get_active_session()"
  },
  {
   "cell_type": "markdown",
   "id": "23627ed5-7e8c-4017-a270-c27af9c06676",
   "metadata": {
    "collapsed": false,
    "name": "EXPLORATION_0"
   },
   "source": [
    "# 2 - Data Exploration & Visualization\n",
    "\n",
    "* `session.table()` creates a reference to a table\n",
    "* `count()`, `order_by()`, `describe()` are dataframe operations\n",
    "* `describe()` gives us insights into the transaction amounts (e.g. min, average, max, count).\n",
    "\n",
    "We can see that we have roughly 50K transactions across 350 customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15bb06-d009-458a-8627-fe407729cbf6",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "EXPLORATION_1"
   },
   "outputs": [],
   "source": [
    "transactions_df = session.table('SIMPLE_MLOPS_DEMO.RETAIL_DATA.TRANSACTIONS')\n",
    "\n",
    "print(f'Number of transactions: {transactions_df.count()}')\n",
    "print(f'Number of customers: {transactions_df.select(\"CUSTOMER_ID\").distinct().count()}')\n",
    "\n",
    "print('Transactions Data:')\n",
    "transactions_df.order_by(col('DATE').desc()).show()\n",
    "\n",
    "print('Quick Variable Analysis:')\n",
    "transactions_df.describe().order_by('SUMMARY').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d374a-b912-4600-a0a4-a3f82d2d1b4d",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": "### Plotting Data\nYou can use libraries such as plotly or matplotlib to visualize your data. However, instead of coding the plots manually, we'll leverage GenAI models hosted natively in Snowflake to automatically generate the visualizations.\n\n* This notebook comes with your own personal ðŸ¤– **CortexPilot** powered by Cortex LLMs   \n    * `ui_plotting()` -> UI-driven plotting with GenAI\n    * `f_cortex_helper_visualize_query()` -> function that receives a Snowpark or Pandas Dataframe and a prompt (in case you already know the dataframe and query)\n\nBoth functions utilize Snowflake's [complete()](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/api/cortex/snowflake.cortex.complete) function to access LLMs natively hosted in Snowflake.\n\nTry asking the following questions:  \n* ***What was the overall revenue per channel and month? Use a stacked bar plot and use YY-Monthname for the x-axis. Make sure the x-axis is ordered.***\n* ***What was the total transaction amount per channel? Use a pie chart.***"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b1910-6162-49c2-adf8-3294baa80b89",
   "metadata": {
    "language": "python",
    "name": "cell40"
   },
   "outputs": [],
   "source": [
    "# Get an instance of CortexPilot\n",
    "my_pilot = CortexPilot(llm='mistral-large2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36330fe-dd5f-41c3-854f-f62d92fa48b6",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# Open the UI\n",
    "my_pilot.ui_plotting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ed6e6-70a3-4f8b-a61c-446cf9eaada8",
   "metadata": {
    "collapsed": false,
    "name": "cell23"
   },
   "source": [
    "When we plot the distribution of ONLINE vs. IN_SHOP revenue, we can see that 75% of our revenue comes from customer transactions that go into our shops.  \n",
    "A model trained on this data should recognize that IN_SHOP transactions are the major driver of future customer revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5466e-03ee-4b0d-a851-6e132ca07f1d",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "my_pilot.f_cortex_helper_visualize_query(transactions_df, 'What was the total transaction amount per channel? Use a pie chart.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0114ca-d50b-4a6b-a33d-ed29b98eb692",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "# 3 - Feature Store & Feature Engineering\n",
    "The Snowflake Feature Store enables data scientists and ML engineers to create, manage, and utilize machine learning features within machine learning pipelines.  \n",
    "A feature store consists of feature views, which encapsulate Python or SQL pipelines that transform raw data into one or more related features.  \n",
    "All features within a feature view are refreshed simultaneously from the source data.\n",
    "\n",
    "Feature store objects are implemented as Snowflake objects and all feature store objects are therefore subject to Snowflake access control rules.\n",
    "| Feature Store Object    | Snowflake Object |\n",
    "| -------- | ------- |\n",
    "| `FeatureStore` | Schema     |\n",
    "| `Entity`    | Tag    |\n",
    "| `FeatureView`  | Dynamic Table or View    |\n",
    "| `Feature`  | Column in a Dynamic Table or View    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c188a-b9d0-4da7-b6ab-7b85c3f3172b",
   "metadata": {
    "collapsed": false,
    "name": "cell26"
   },
   "source": [
    "### Setup the Feature Store\n",
    "We are creating (or referencing if it already exists) a Feature Store that is stored in the schema `FEATURE_STORE`.  \n",
    "The `default_warehouse` will be used to refresh features automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db378dc4-44e5-4b5b-b55c-e1a3e14ec663",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database='SIMPLE_MLOPS_DEMO', \n",
    "    name='FEATURE_STORE', \n",
    "    default_warehouse='FEATURE_STORE_WH',\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00471e-18fd-47d0-99ae-8b945e7b0bdb",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "### Create a Feature Store Entity\n",
    "Feature views are organized in the feature store according to the entities to which they apply. An entity is a higher-level abstraction that represents the subject matter of a feature.  \n",
    "In our example, the main entity is the `CUSTOMER` and the features we will create will be linked to this entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4286517a-2a63-4565-aa22-63104d78f21b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "# Create a new entity for the Feature Store\n",
    "entity = Entity(name=\"CUSTOMER\", join_keys=[\"CUSTOMER_ID\"], desc='Unique identifier for customers.')\n",
    "fs.register_entity(entity)\n",
    "fs.list_entities().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc666d-c1be-484d-b203-4fc26b99cf88",
   "metadata": {
    "collapsed": false,
    "name": "cell31"
   },
   "source": [
    "### Develop Features for Customer Transactions\n",
    "\n",
    "The Snowpark Python API provides analytics functions for easily defining many common feature types, such as windowed aggregations.  \n",
    "We will use `analytics.time_series_agg()` to quickly generate revenue for the past 1, 2 and 3 months per customer per channel which we will use as features for our machine learning model.\n",
    "\n",
    "The feature dataframe should have the following columns:\n",
    "| Column    | Purpose |\n",
    "| -------- | ------- |\n",
    "| `CUSTOMER_ID` | Identify relevant rows for the calculated feature (Join-Criteria)     |\n",
    "| `DATE`    | Allow correct Point-in-Time Joins   |\n",
    "| `Feature columns`  | Actual features per entity    |  \n",
    "\n",
    "You can find more functions for quickly generating featueres here:  \n",
    "[Common feature and query patterns](https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdfdb0-10fb-4891-8c06-81c1c7dd0af3",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "def col_formatter(input_col, agg, window):\n",
    "    feature_name = f\"{agg.replace('SUM','TOTAL')}_{input_col}_{window.replace('-', 'past_').replace('MM','_MONTHS')}\"\n",
    "    return feature_name\n",
    "\n",
    "in_shop_transaction_features = (\n",
    "    transactions_df.filter(col('TRANSACTION_CHANNEL') == 'IN_SHOP')\n",
    "    .group_by(['CUSTOMER_ID','DATE']).agg(F.sum('TRANSACTION_AMOUNT').as_('REVENUE'))\n",
    "    .rename({'REVENUE':'REVENUE_IN_SHOP'})\n",
    "    .analytics.time_series_agg(\n",
    "        aggs={'REVENUE_IN_SHOP':['SUM']},\n",
    "        windows=['-1MM','-2MM','-3MM'],\n",
    "        sliding_interval=\"1D\",\n",
    "        group_by=['CUSTOMER_ID'],\n",
    "        time_col='DATE',\n",
    "        col_formatter=col_formatter\n",
    "    ).drop(['SLIDING_POINT','REVENUE_IN_SHOP'])\n",
    ")\n",
    "\n",
    "online_transaction_features = (\n",
    "    transactions_df.filter(col('TRANSACTION_CHANNEL') == 'ONLINE')\n",
    "    .group_by(['CUSTOMER_ID','DATE']).agg(F.sum('TRANSACTION_AMOUNT').as_('REVENUE'))\n",
    "    .rename({'REVENUE':'REVENUE_ONLINE'})\n",
    "    .analytics.time_series_agg(\n",
    "        aggs={'REVENUE_ONLINE':['SUM']},\n",
    "        windows=['-1MM','-2MM','-3MM'],\n",
    "        sliding_interval=\"1D\",\n",
    "        group_by=['CUSTOMER_ID'],\n",
    "        time_col='DATE',\n",
    "        col_formatter=col_formatter\n",
    "    ).drop(['SLIDING_POINT','REVENUE_ONLINE'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f6ecc-65d2-4b18-9386-ee4dbd649a2a",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "online_transaction_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32994363-a331-4cf0-b156-aa3575776d69",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "**Feature Descriptions**  \n",
    "To avoid manually writing descriptions, we can use `complete()` to have an LLM generate JSON files containing business descriptions.  \n",
    "The CortexPilot also offers a convenient function `f_describe_columns()` based on the complete() function.  \n",
    "These descriptions are stored in the Feature Store alongside our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f25bcab-5a03-4745-bb60-399b3d4a2947",
   "metadata": {
    "language": "python",
    "name": "cell71"
   },
   "outputs": [],
   "source": [
    "feature_descriptions_in_shop_transactions = my_pilot.f_describe_columns(in_shop_transaction_features, exclude_columns=['CUSTOMER_ID','DATE'])\n",
    "feature_descriptions_online_transactions = my_pilot.f_describe_columns(online_transaction_features, exclude_columns=['CUSTOMER_ID','DATE'])\n",
    "\n",
    "st.json(feature_descriptions_in_shop_transactions)\n",
    "st.json(feature_descriptions_online_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfb016-65ea-4690-813f-54084735c0a0",
   "metadata": {
    "collapsed": false,
    "name": "cell22"
   },
   "source": [
    "### Registering Feature Views\n",
    "The `FeatureView` class accepts a Snowpark DataFrame object that contains the feature transformation logic. This allows you to define your features using any method supported by the Snowpark DataFrame API or Snowflake SQL. You can pass the DataFrame directly to the `FeatureView` constructor.  \n",
    "\n",
    "Each `FeatureView` is associated with the corresponding `Entity`.  \n",
    "The `refresh_freq` parameter determines how often the Feature Store checks for new data and updates the features automatically. For demonstration purposes, this value is set to 1 minute, but it should be adjusted based on the specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d69f38-03c7-435e-8240-7795f752e418",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "# Create Feature View\n",
    "in_shop_transaction_fv = FeatureView(\n",
    "    name=\"IN_SHOP_REVENUE_FEATURES\", \n",
    "    entities=[entity],\n",
    "    timestamp_col='DATE',\n",
    "    feature_df=in_shop_transaction_features, \n",
    "    refresh_freq=\"1 minute\",\n",
    "    refresh_mode='AUTO',\n",
    "    desc=\"Features for in-shop transactions\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Add descriptions for features\n",
    "in_shop_transaction_fv = in_shop_transaction_fv.attach_feature_desc(feature_descriptions_in_shop_transactions)\n",
    "\n",
    "in_shop_transaction_fv = fs.register_feature_view(\n",
    "    feature_view=in_shop_transaction_fv, \n",
    "    version=\"V1\", \n",
    "    block=True,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Create Feature View\n",
    "online_transaction_fv = FeatureView(\n",
    "    name=\"ONLINE_REVENUE_FEATURES\", \n",
    "    entities=[entity],\n",
    "    timestamp_col='DATE',\n",
    "    feature_df=online_transaction_features, \n",
    "    refresh_freq=\"1 minute\",\n",
    "    refresh_mode='AUTO',\n",
    "    desc=\"Features for online transactions\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Add descriptions for features\n",
    "online_transaction_fv = online_transaction_fv.attach_feature_desc(feature_descriptions_online_transactions)\n",
    "\n",
    "online_transaction_fv = fs.register_feature_view(\n",
    "    feature_view=online_transaction_fv, \n",
    "    version=\"V1\", \n",
    "    block=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70565143-a46f-4dd6-aaa4-483ea055f37f",
   "metadata": {
    "collapsed": false,
    "name": "cell63"
   },
   "source": [
    "### Discovering Features via Feature Store UI\n",
    "After creating entities and feature views, you can utilize the [Feature Store User Interface](https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/feature-store-ui) in Snowsight to locate the objects you need.  \n",
    "\n",
    "Example of the Feature Store UI:  \n",
    "![text](https://github.com/michaelgorkow/snowflake_simple_mlops/blob/main/resources/feature_store.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc112af7-52a7-423f-8161-d5b27a20f53d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "URL_FEATURE_STORE"
   },
   "outputs": [],
   "source": [
    "get_snowsight_url(session, 'Link to Feature Store', '#/features/database/SIMPLE_MLOPS_DEMO/store/FEATURE_STORE/entities')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51761481-2cbe-45d8-9bb7-6529577b0871",
   "metadata": {
    "collapsed": false,
    "name": "cell64"
   },
   "source": [
    "### Discovering Features via Feature Store API\n",
    "If you don't want to use the UI or want to develop workflows based on data in the feature store you can use the [Feature Store APIs](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/feature_store).  \n",
    "\n",
    "CortexPilot can also help you in understanding how certain columns in a SQL query are calculated. In this example we are asking how a certain feature in the feature store is calculated but it works for any SQL query.  \n",
    "Simply call `f_explain_column_sql` with the column name and the SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc6acb-fd8b-4c41-bf39-24e5fe74affb",
   "metadata": {
    "language": "python",
    "name": "cell66"
   },
   "outputs": [],
   "source": [
    "st.markdown('### List of all Feature Views:')\n",
    "sdf(fs.list_feature_views())\n",
    "\n",
    "# Retrieve a Feature View\n",
    "retrieved_feature_view = fs.get_feature_view(name='IN_SHOP_REVENUE_FEATURES',version='V1')\n",
    "\n",
    "st.markdown('### Feature View Columns:')\n",
    "sdf(retrieved_feature_view.list_columns())#.show(max_width=200)\n",
    "\n",
    "# Manually refresh a Feature View\n",
    "fs.refresh_feature_view(retrieved_feature_view)\n",
    "\n",
    "st.markdown('### Feature View Refresh History:')\n",
    "sdf(fs.get_refresh_history(retrieved_feature_view).order_by(col('REFRESH_END_TIME').desc()).limit(3))\n",
    "\n",
    "# Explore lineage information\n",
    "st.markdown('### Feature View Lineage:')\n",
    "st.json(retrieved_feature_view.lineage(direction='both'))\n",
    "\n",
    "# Use an LLM and the underlying SQL query to explain how the feature is calculated\n",
    "st.markdown('### LLM Explanation for a Feature in the Feature Store:')\n",
    "sql_explanation = my_pilot.f_explain_column_sql(column='TOTAL_REVENUE_IN_SHOP_PAST_1_MONTHS', sql_query=retrieved_feature_view.query)\n",
    "st.markdown(sql_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade4851-3069-4d9a-af29-8c650c1f1cf5",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "# 4 - Model Training\n",
    "\n",
    "### Generate the Training Dataset with Features from Feature Store\n",
    "Our goal is to predict each customer's revenue for the next month based on their transactions from the past three months.  \n",
    "\n",
    "We have data from January to April 2024. To define our target variable, `NEXT_MONTH_REVENUE`, we sum all transactions from April for each customer. To ensure proper point-in-time feature retrieval and avoid using future data, we only include transaction features up to **April 1st, 2024**, and mark this cutoff with the `FEATURE_CUTOFF_DATE` column.  \n",
    "\n",
    "The DataFrame you just created is a **spine DataFrame**, which acts as a reference table linking customers (`CUSTOMER_ID`) with a timestamp (`FEATURE_CUTOFF_DATE`). It ensures consistent and reproducible feature retrieval in a **feature store**.  \n",
    "\n",
    "Using this spine, you can generate a training dataset with [`generate_dataset()`](https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/modeling#generating-snowflake-datasets-for-training). The Feature Store will automatically retrieve features as they were valid on that date and add them to the dataset.  \n",
    "\n",
    "A [Snowflake Dataset](https://docs.snowflake.com/en/developer-guide/snowflake-ml/dataset) is a schema-level object designed for machine learning. It stores data in versions, ensuring immutability, efficient access, and compatibility with ML frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ebd1e-0700-4646-a3ff-d871e51d3fc6",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "target_df = session.table('SIMPLE_MLOPS_DEMO.RETAIL_DATA.TRANSACTIONS')\n",
    "target_df = (\n",
    "    target_df.filter(col('DATE').between('2024-04-02','2024-05-01'))    # Generate Target Variable for April 2024\n",
    "    .group_by('CUSTOMER_ID')\n",
    "    .agg(F.sum('TRANSACTION_AMOUNT').as_('NEXT_MONTH_REVENUE'))\n",
    "    .with_column('FEATURE_CUTOFF_DATE', F.to_date(lit('2024-04-01')))   # Features until End of March 2024\n",
    ")\n",
    "\n",
    "# Get list of all customers\n",
    "customers_df = session.table('SIMPLE_MLOPS_DEMO.RETAIL_DATA.CUSTOMERS').select('CUSTOMER_ID').distinct()\n",
    "\n",
    "# Create spine dataframe\n",
    "spine_df = target_df.join(customers_df, on=['CUSTOMER_ID'], how='outer')\n",
    "spine_df = spine_df.fillna(0, subset='NEXT_MONTH_REVENUE')\n",
    "spine_df.order_by('CUSTOMER_ID').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43830e-d929-4fdf-a94a-f6761e09fa6b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "train_dataset = fs.generate_dataset(\n",
    "    name=\"SIMPLE_MLOPS_DEMO.FEATURE_STORE.NEXT_MONTH_REVENUE_DATASET\",\n",
    "    spine_df=spine_df,\n",
    "    features=[in_shop_transaction_fv, online_transaction_fv],\n",
    "    version=\"V1\",\n",
    "    spine_timestamp_col=\"FEATURE_CUTOFF_DATE\",\n",
    "    spine_label_cols=[\"NEXT_MONTH_REVENUE\"],\n",
    "    include_feature_view_timestamp_col=False,\n",
    "    desc=\"Initial Training Dataset\"\n",
    ")\n",
    "\n",
    "df = train_dataset.read.to_snowpark_dataframe()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d081cd-ff03-4efa-9134-ae34a29e0190",
   "metadata": {
    "collapsed": false,
    "name": "cell32"
   },
   "source": [
    "### Train an XGBoost Model\n",
    "We randomly split the data, allocating **90% for training** and **10% for validation**.  \n",
    "The training data is then used to train an **XGBoost regression model** with the `XGBRegressor` from the **Snowflake ML library**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbea5f6-0020-4465-add6-8a87653644ac",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_df, test_df = df.random_split(weights=[0.9, 0.1], seed=0)\n",
    "\n",
    "print(f'Number of samples in train: {train_df.count()}')\n",
    "print(f'Number of samples in test: {test_df.count()}')\n",
    "\n",
    "feature_columns = train_df.drop(['CUSTOMER_ID','FEATURE_CUTOFF_DATE','NEXT_MONTH_REVENUE']).columns\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    input_cols=feature_columns,\n",
    "    label_cols=['NEXT_MONTH_REVENUE'],\n",
    "    output_cols=['NEXT_MONTH_REVENUE_PREDICTION'],\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "xgb_model = xgb_model.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca74d9a-0504-48ae-a6ab-b399a56f2d56",
   "metadata": {
    "collapsed": false,
    "name": "cell24"
   },
   "source": [
    "### Evaluate the XGBoost Model\n",
    "You can immediately use the modelâ€™s `predict()` function to generate predictions on the test data.  \n",
    "Snowflake ML also provides built-in metric functions, such as **Mean Absolute Percentage Error (MAPE)**, for evaluating model performance.  \n",
    "\n",
    "Additionally, you can convert the model back to its native open-source format using `xgb_model.to_xgboost()`.  \n",
    "This allows you to access feature importance values, which we visualize to better understand what influences the modelâ€™s predictions.  \n",
    "\n",
    "As shown in the plot, the model correctly identified that **IN_SHOP transactions** are the primary driver of the target variable, `NEXT_MONTH_REVENUE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737ef58-d313-4138-91e7-bb5becf601ea",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": "predictions = xgb_model.predict(test_df)\n# Analyze results\nmape = mean_absolute_percentage_error(\n    df=predictions, \n    y_true_col_names=\"NEXT_MONTH_REVENUE\", \n    y_pred_col_names=\"NEXT_MONTH_REVENUE_PREDICTION\"\n)\n\nst.info(f\"**Mean absolute percentage error:** {mape:.5f}\")\n\ncol1, col2 = st.columns(2)\nwith col1:\n    # Plot Feature Importance\n    plot_data = pd.DataFrame(\n        list(zip(feature_columns, xgb_model.to_xgboost().feature_importances_)), \n        columns=['FEATURE','IMPORTANCE']\n    )\n    \n    fig = px.bar(\n        plot_data.sort_values('IMPORTANCE', ascending=True).head(10),\n        x=\"IMPORTANCE\",\n        y=\"FEATURE\",\n        title=\"Feature Importance\",\n        labels={\"FEATURE\": \"Feature\", \"IMPORTANCE\": \"Importance\"},\n        orientation=\"h\"\n    )\n    fig.update_layout(title_font=dict(size=20, family=\"Arial\", color=\"black\"))\n    st.plotly_chart(fig, use_container_width=True)\nwith col2:\n    # Plot Predictions\n    fig = px.scatter(\n        predictions[\"NEXT_MONTH_REVENUE\", \"NEXT_MONTH_REVENUE_PREDICTION\"].to_pandas().astype(\"float64\"),\n        x=\"NEXT_MONTH_REVENUE\",\n        y=\"NEXT_MONTH_REVENUE_PREDICTION\",\n        title=\"Actual vs. Predicted Revenue\",\n        labels={\n            \"NEXT_MONTH_REVENUE\": \"Actual Revenue\",\n            \"NEXT_MONTH_REVENUE_PREDICTION\": \"Predicted Revenue\"\n        },\n        trendline=\"ols\",\n        trendline_color_override=\"red\"\n    )\n    fig.update_layout(title_font=dict(size=20, family=\"Arial\", color=\"black\"))\n    st.plotly_chart(fig, use_container_width=True)"
  },
  {
   "cell_type": "markdown",
   "id": "720ad317-43d5-44d8-a66e-18abf67e4a28",
   "metadata": {
    "collapsed": false,
    "name": "cell33"
   },
   "source": [
    "# 5 - Snowflake Model Registry\n",
    "### Setup Model Registry\n",
    "After training a model, the first step in operationalizing it and running inference in Snowflake is to **log the model in the Snowflake Model Registry**.  \n",
    "\n",
    "The **Model Registry** allows you to securely manage models and their metadata in Snowflake, regardless of their origin or type, while also simplifying inference.  \n",
    "It stores machine learning models as **first-class schema-level objects** within Snowflake.  \n",
    "\n",
    "By setting `enable_monitoring` to True, the **Model Registry** can also be used for model monitoring, which we will implement in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570b13e-2b1d-480f-8a0b-e73488f7e3c6",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": [
    "# Create reference to model registry\n",
    "reg = Registry(\n",
    "    session=session, \n",
    "    database_name='SIMPLE_MLOPS_DEMO', \n",
    "    schema_name='MODEL_REGISTRY', \n",
    "    options={'enable_monitoring':True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d2ca7-7f49-4692-ad0a-aedcc614d322",
   "metadata": {
    "collapsed": false,
    "name": "cell34"
   },
   "source": [
    "### Register Model in Model Registry\n",
    "The Model Registry's `log_model()` function takes the model object and logs it to the registry.  \n",
    "The **name** and **version** help ensure the correct model is retrieved for inference.  \n",
    "\n",
    "Additionally, we log relevant metrics/information, including:  \n",
    "- **MAPE (Mean Absolute Percentage Error)** calculated on the test dataset  \n",
    "- **FEATURE_CUTOFF_DATE**   \n",
    "\n",
    "We also specify the following parameters:  \n",
    "\n",
    "| Variable               | Description  |\n",
    "|------------------------|-------------|\n",
    "| `sample_input_data`    | Sample input data used to infer model signatures, serve as background data for explanations, and capture data lineage. |\n",
    "| `conda_dependencies`   | Specifies model dependencies, such as the XGBoost library. |\n",
    "| `relax_version`        | Enforces specific dependency versions for compatibility and reproducibility. |\n",
    "| `enable_explainability` | Adds an explainability function to the model, allowing us to better understand its predictions using SHAP values. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18434961-96fe-482a-90c5-40ea4ba8402b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": [
    "registered_model = reg.log_model(\n",
    "    xgb_model,\n",
    "    model_name=\"CUSTOMER_REVENUE_MODEL\",\n",
    "    version_name='V1',\n",
    "    metrics={\n",
    "        'MAPE':mape, \n",
    "        \"TRAINING_DATA\":{'FEATURE_CUTOFF_DATE':'2024-04-01'}\n",
    "    },\n",
    "    comment=\"Model trained using XGBoost to predict revenue per customer for next month.\",\n",
    "    conda_dependencies=['xgboost'],\n",
    "    sample_input_data=train_df.select(feature_columns).limit(100),\n",
    "    options={\"relax_version\": False, \"enable_explainability\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6492927-bcca-4f8d-93c2-bb7fe490d466",
   "metadata": {
    "collapsed": false,
    "name": "cell41"
   },
   "source": [
    "### Operationalize Models\n",
    "There are multiple ways to operationalize models using Snowflake's Model Registry.  \n",
    "One simple approach is to use **aliases** for the model. By assigning the alias **`PRODUCTION`**, any inference pipeline referencing this alias will automatically use the correct production-ready model.  \n",
    "\n",
    "When a new model version is trained and ready for deployment, you can seamlessly update production by **removing the alias from the current model** and **assigning it to the new model**.  \n",
    "This method ensures that existing ML pipelines remain unchanged, reducing the need for manual updates while maintaining a smooth model deployment process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141827b-939f-4e43-983d-7854519e5ab7",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell30"
   },
   "outputs": [],
   "source": [
    "registered_model.set_alias('PRODUCTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c8eac-0ad9-4ed6-9f7d-c31c45b91cc8",
   "metadata": {
    "language": "python",
    "name": "cell42"
   },
   "outputs": [],
   "source": [
    "# Retrieve the production model in your pipelines like this\n",
    "production_model = reg.get_model('CUSTOMER_REVENUE_MODEL').version('PRODUCTION')\n",
    "production_model.show_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ebd58e-640b-4442-8155-c64f8bad43d5",
   "metadata": {
    "collapsed": false,
    "name": "cell62"
   },
   "source": [
    "### Explore Models in the Model Registry UI\n",
    "The [Model Registry UI]((https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/snowsight-ui)) in Snowsight enables you to discover and explore machine learning models available for use in Snowflake.  \n",
    "\n",
    "To view a model's details, click on its corresponding row in the Models list.  \n",
    "The details page provides essential information, including the model's description, tags, and versions.\n",
    "\n",
    "Example of the Model Registry UI:  \n",
    "![text](https://github.com/michaelgorkow/snowflake_simple_mlops/blob/main/resources/model_registry_ui.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08a60d-bdc8-45e8-9558-8b999d94e2b0",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "URL_MODEL_REGISTRY"
   },
   "outputs": [],
   "source": [
    "get_snowsight_url(session, 'Link to Model Registry', '#/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6642c-5fe5-4361-b970-2955611795cb",
   "metadata": {
    "collapsed": false,
    "name": "cell48"
   },
   "source": "### **Model Explainability**\nSince we enabled `model_explainability` during model registration, we can now use the auto-generated `explain` function to compute SHAP values for each feature.\n\n#### **What are SHAP (SHapley Additive exPlanations) values?**  \nSHAP values provide a game-theoretic approach to interpreting machine learning predictions by fairly attributing contributions to each feature. They help explain both **global feature importance** and **individual predictions**, showing how each feature increases or decreases the modelâ€™s output. **Positive SHAP values** indicate features that push the prediction higher, while **negative values** lower it relative to the modelâ€™s baseline prediction.\n\nOnce computed, we can convert the SHAP values into a native [`shap.Explanation`](https://shap.readthedocs.io/en/latest/generated/shap.Explanation.html) object, which includes:\n\n| Variable        | Description |\n|----------------|-------------|\n| `values`       | Contribution of each feature to the prediction (output from Snowflakeâ€™s `explain` function). |\n| `base_values`  | Expected model output (typically the mean prediction). |\n| `data`         | Feature values (used for visualization). |\n| `feature_names` | Names of the features (optional but recommended). |\n\nYou can then leverage SHAP's built-in functions for visualization and deeper analysis."
  },
  {
   "cell_type": "code",
   "id": "a9f54e45-44e8-481d-ba8c-486f7a54080b",
   "metadata": {
    "language": "python",
    "name": "cell88"
   },
   "outputs": [],
   "source": "# Calculate Shap values predictions\nexplanations = production_model.run(predictions, function_name=\"explain\")\nexplanations = explanations.rename({col:col.replace('\"\"\"', '').upper() for col in explanations.columns})\nshap_columns = [col for col in explanations.columns if '_EXPLANATION' in col]\nexplanations = explanations.to_pandas()\n\n# Create the native shap Explanation object\nshap_exp = shap.Explanation(\n    values = explanations[shap_columns].values,\n    base_values = np.full((len(explanations),), explanations['NEXT_MONTH_REVENUE_PREDICTION'].mean()),\n    data = explanations[feature_columns].values,\n    feature_names=feature_columns\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6badc161-aaf8-42f0-ac1f-c8a3a5fcd653",
   "metadata": {
    "name": "cell90",
    "collapsed": false
   },
   "source": "### Global Explainibility using SHAP\n\nThe **left plot** is a SHAP **summary plot**, which displays the impact of each feature on the modelâ€™s output. Each dot represents a single instance, with the color indicating the feature value (blue = low, pink = high). Features at the top are the most influential, and the x-axis shows whether they push predictions higher (positive SHAP values) or lower (negative SHAP values).  \n\nThe **right plot** is a SHAP **violin plot**, which shows the distribution of SHAP values for each feature. The width of the violin indicates the density of SHAP values, helping visualize how much a featureâ€™s impact varies across different predictions. Both plots highlight that recent revenue metrics (e.g., \"TOTAL_REVENUE_IN_SHOP_PAST_1_MONTH\") strongly influence the model, with high revenue values generally increasing predictions."
  },
  {
   "cell_type": "code",
   "id": "471ab482-1ce4-4359-b7ef-2fb035406855",
   "metadata": {
    "language": "python",
    "name": "cell92"
   },
   "outputs": [],
   "source": "col1, col2 = st.columns(2)\nwith col1:\n    shap.summary_plot(shap_exp)\nwith col2:\n    shap.plots.violin(shap_exp)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa24ab41-8665-495e-8917-d3e9546aea64",
   "metadata": {
    "name": "cell93",
    "collapsed": false
   },
   "source": "### Local Explainibility using SHAP\n\nOn the left you see a **SHAP waterfall plot** which explains how a model arrived at a specific prediction by showing feature contributions. It starts with the **expected value** (baseline prediction) and adjusts it based on **SHAP values** of individual features. **Blue bars** represent features that **lowered** the prediction, while **red bars** indicate those that **increased** it. The final predicted value is obtained by sequentially adding these contributions to the baseline. This plot helps identify which features had the most impact and whether they pushed the prediction up or down.\n\nOn the right we are plotting the distribution of **online vs. in-shop transaction** for this specific customer."
  },
  {
   "cell_type": "code",
   "id": "c61f9eff-c039-4401-bc33-7f7c053ed2b4",
   "metadata": {
    "language": "python",
    "name": "cell87"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\nselected_customer = st.selectbox('Select Customer:', explanations.sort_values(by='CUSTOMER_ID')['CUSTOMER_ID'].values)\nindex = explanations.index[explanations['CUSTOMER_ID'] == selected_customer][0]\ncol1, col2 = st.columns([0.6,0.4])\nwith col1:\n    st.subheader('Shap Summary Plot')\n    fig, ax = plt.subplots()\n    ax.set_title(\"\", fontsize=16)\n    plt.sca(ax)\n    shap.plots.waterfall(shap_exp[index], show=False)\n    plt.close()\n    st.pyplot(fig)\nwith col2:\n    st.subheader('Customer Transaction ')\n    demo_flow.get_customer_revenue_plot(transactions_df, int(index))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e0a85689-b808-48ca-8c7c-cb3c307b59c0",
   "metadata": {
    "collapsed": false,
    "name": "cell35"
   },
   "source": [
    "### Continious Model Monitoring\n",
    "Model behavior can change over time due to factors such as **input drift, stale training assumptions, data pipeline issues, hardware and software updates**.\n",
    "\n",
    "**ML Observability** enables you to monitor the quality of models registered in the **Snowflake Model Registry** across multiple dimensions, including **performance, drift, and volume**.  \n",
    "\n",
    "To measure drift for model monitoring, we use two tables:  \n",
    "\n",
    "| Table      | Description  |\n",
    "|------------|-------------|\n",
    "| `BASELINE` | Contains a snapshot of data similar to `SOURCE`. It is used as a reference for comparing future feature values and predictions. |\n",
    "| `SOURCE`   | Stores future predictions and feature values for monitoring. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10552343-1009-4e62-989d-6afbbef0e1cb",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell44"
   },
   "outputs": [],
   "source": [
    "# Save baseline predictions\n",
    "predictions = predictions.with_column('FEATURE_CUTOFF_DATE', F.col('FEATURE_CUTOFF_DATE').cast('timestamp'))\n",
    "predictions.write.save_as_table('SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_BASELINE_V1', mode='overwrite')\n",
    "predictions.write.save_as_table('SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_SOURCE_V1', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d3f43e-0b16-4e68-a0f8-79d9be5edd1c",
   "metadata": {
    "collapsed": false,
    "name": "cell54"
   },
   "source": "### Creating predictions for the next month\nWe now use the trained model on our **April data** to predict each customer's **revenue for May**.  \nThe workflow looks like this:  \n1. Build a spine DataFrame\n2. Retrieve Features from Feature Store \n3. Generate predictions\n\nNow, letâ€™s take this a step further with a **real-world challenge**:  \nImagine you didnâ€™t train the model yourself. How would you determine which input features are required and where to source them?\n\nThe answer is simple:  \nQuery the **automatically captured lineage** information in Snowflake!  \nThe model is directly linked to the dataset used for training, which in turn is connected to the relevant Feature Views."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e3b1f-6058-499d-90b7-ff1af87abb26",
   "metadata": {
    "language": "python",
    "name": "cell51"
   },
   "outputs": [],
   "source": "feature_views = production_model.lineage(direction='upstream')[0].lineage(domain_filter=['feature_view'], direction='upstream')\n[fv.name for fv in feature_views]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0419c0-d00d-47ae-baf5-6737ef8383be",
   "metadata": {
    "language": "python",
    "name": "cell47"
   },
   "outputs": [],
   "source": [
    "def get_feature_df(model, feature_cutoff_date):\n",
    "    # Use lineage information to retrieve the feature views of this model\n",
    "    feature_views = model.lineage(direction='upstream')[0].lineage(domain_filter=['feature_view'], direction='upstream')\n",
    "    \n",
    "    # Create the spine dataframe containing all customers\n",
    "    spine_df = (\n",
    "        session.table('SIMPLE_MLOPS_DEMO.RETAIL_DATA.CUSTOMERS')\n",
    "        .select('CUSTOMER_ID')\n",
    "        .with_column('FEATURE_CUTOFF_DATE', F.to_date(lit(feature_cutoff_date)))\n",
    "    )\n",
    "\n",
    "    # Retrieve feature values from the Feature Store for the specified cutoff date.\n",
    "    feature_df = fs.retrieve_feature_values(\n",
    "        spine_df=spine_df,\n",
    "        features=feature_views,\n",
    "        spine_timestamp_col=\"FEATURE_CUTOFF_DATE\"\n",
    "    )\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a038b00-0e99-47fc-8dcf-e5828e05410a",
   "metadata": {
    "language": "python",
    "name": "cell50"
   },
   "outputs": [],
   "source": [
    "feature_df = get_feature_df(\n",
    "    production_model, \n",
    "    feature_cutoff_date='2024-05-01', \n",
    ")\n",
    "\n",
    "predictions = production_model.run(feature_df, function_name='PREDICT')\n",
    "predictions.write.save_as_table(table_name='SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_SOURCE_V1', mode='append', column_order='name')\n",
    "\n",
    "# View predictions\n",
    "print('Predictions [column=NEXT_MONTH_REVENUE_PREDICTION]:')\n",
    "session.table('SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_SOURCE_V1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca5a9b-1bbb-44a4-a8c0-05d360c8f5e8",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "### Creating a Model Monitor  \n",
    "\n",
    "We are setting up a **model monitor** to continuously calculate and track model performance and drift over time.  \n",
    "\n",
    "These calculations are based on the **`BASELINE`** and **`SOURCE`** tables created earlier.  \n",
    "Each model requires its own dedicated **model monitor** to ensure accurate tracking and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2614e2f-4856-4e5b-a5a5-d78b4f3eeaea",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "source_config = ModelMonitorSourceConfig(\n",
    "    source='SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_SOURCE_V1',\n",
    "    timestamp_column='FEATURE_CUTOFF_DATE',\n",
    "    id_columns=['CUSTOMER_ID'],\n",
    "    prediction_score_columns=['NEXT_MONTH_REVENUE_PREDICTION'],\n",
    "    actual_score_columns=['NEXT_MONTH_REVENUE'],\n",
    "    baseline='SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_BASELINE_V1'\n",
    ")\n",
    "\n",
    "monitor_config = ModelMonitorConfig(\n",
    "    model_version=reg.get_model('CUSTOMER_REVENUE_MODEL').version('PRODUCTION'),\n",
    "    model_function_name='predict',\n",
    "    background_compute_warehouse_name='COMPUTE_WH',\n",
    "    refresh_interval='1 minute',\n",
    "    aggregation_window='1 day'\n",
    ")\n",
    "\n",
    "model_monitor = reg.add_monitor(\n",
    "    name='SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_V1',\n",
    "    source_config=source_config,\n",
    "    model_monitor_config=monitor_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64990a-9de7-42f5-af03-525cf41a057a",
   "metadata": {
    "collapsed": false,
    "name": "cell53"
   },
   "source": [
    "### Simulating the next month of Customer Transactions\n",
    "Our model has predicted each customer's **revenue for May 2024** and stored the results in the **`SOURCE`** table.  \n",
    "Next, we simulate the actual transactions for May and update the **true revenue values** for each customer in the **`SOURCE`** table.  \n",
    "When the **model monitor** refreshes, it will use these updated values to calculate various **model performance metrics**, including the MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa1731-d7d4-4aff-bf0a-1e4f2b36a286",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell49"
   },
   "outputs": [],
   "source": [
    "# Add new transactions (created as part of the initial demo setup)\n",
    "new_transactions = session.table('SIMPLE_MLOPS_DEMO._DATA_GENERATION._TRANSACTIONS').filter(col('DATE').between('2024-05-02','2024-06-01'))\n",
    "new_transactions.write.save_as_table(table_name='SIMPLE_MLOPS_DEMO.RETAIL_DATA.TRANSACTIONS', mode='append')\n",
    "\n",
    "# Calculate actual values\n",
    "actual_values_df = (\n",
    "    session.table('SIMPLE_MLOPS_DEMO.RETAIL_DATA.TRANSACTIONS')\n",
    "    .filter(col('DATE').between('2024-05-02','2024-06-01'))\n",
    "    .group_by(['CUSTOMER_ID'])\n",
    "    .agg(F.sum('TRANSACTION_AMOUNT').as_('TOTAL_REVENUE'))\n",
    "    .with_column('DATE', F.to_date(lit('2024-05-01')))\n",
    ")\n",
    "\n",
    "# Get list of all customers\n",
    "customers_df = session.table('SIMPLE_MLOPS_DEMO.RETAIL_DATA.CUSTOMERS').select('CUSTOMER_ID').distinct()\n",
    "\n",
    "# Assume 0 revenue for customers without transactions\n",
    "actual_values_df = actual_values_df.join(customers_df, on=['CUSTOMER_ID'], how='outer')\n",
    "actual_values_df = actual_values_df.fillna(0,subset='TOTAL_REVENUE')\n",
    "\n",
    "# Update source table from model monitor\n",
    "source_table = session.table('SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_SOURCE_V1')\n",
    "source_table.update(\n",
    "    condition=(\n",
    "        (source_table['FEATURE_CUTOFF_DATE'] == actual_values_df['DATE']) &\n",
    "        (source_table['CUSTOMER_ID'] == actual_values_df['CUSTOMER_ID'])\n",
    "    ),\n",
    "    assignments={\n",
    "        \"NEXT_MONTH_REVENUE\": actual_values_df['TOTAL_REVENUE'],\n",
    "    },\n",
    "    source=actual_values_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e684bbe-dac6-4f97-8bc4-ca1e6afdd5ee",
   "metadata": {
    "collapsed": false,
    "name": "cell39"
   },
   "source": [
    "## Simulate Customer Transactions until February 2025\n",
    "For convenience, I encapsulated all the logic for simulating future months into the helper function `simulate_model_performance()`.  \n",
    "We use this function to simulate the model's behavior until February 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafe355-8bb7-4d24-9fa7-80bd55514f0d",
   "metadata": {
    "language": "python",
    "name": "cell43"
   },
   "outputs": [],
   "source": [
    "start_date = '2024-06-01'\n",
    "end_date = '2025-01-01'\n",
    "demo_flow.simulate_model_performance(production_model, start_date, end_date, generate_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c08704-b178-40b7-888b-7b4b0c75eac7",
   "metadata": {
    "collapsed": false,
    "name": "cell46"
   },
   "source": [
    "## Explore the Model Monitor\n",
    "Navigate to the Model Monitor and observe the `MAPE` and `Jensen-Shannon Distance`  for the last months.  \n",
    "\n",
    "You will notice the following:\n",
    "* Declining Model Performance\n",
    "    * :chart_with_upwards_trend: MAPE (Mean Average Percentage Error)\n",
    "* Feature Drift\n",
    "    * :chart_with_upwards_trend: Distance for TOTAL_REVENUE_IN_SHOP_PAST_1_MONTHS (less in shop transaction volume)\n",
    "    * :chart_with_downwards_trend: Difference for TOTAL_REVENUE_ONLINE_PAST_1_MONTHS (more online transaction volume)\n",
    "\n",
    "Why is that?  \n",
    "Well, if we visualize the monthly revenue distribution, we can see that online revenue grew while in-shop transaction declined.\n",
    "\n",
    "Instead of using the builtin UI, you can also query model monitor metrics using the following table functions and build your own visuals:\n",
    "* [MODEL_MONITOR_PERFORMANCE_METRIC](https://docs.snowflake.com/en/sql-reference/functions/model-monitor-performance-metric)\n",
    "* [MODEL_MONITOR_DRIFT_METRIC](https://docs.snowflake.com/en/sql-reference/functions/model-monitor-drift-metric)\n",
    "* [MODEL_MONITOR_STAT_METRIC](https://docs.snowflake.com/en/sql-reference/functions/model-monitor-stat-metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd70e5-503c-4952-89b8-f80a1a33434e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "URL_MODEL_MONITOR"
   },
   "outputs": [],
   "source": [
    "get_snowsight_url(session, 'Link to Model Monitor', '#/data/databases/SIMPLE_MLOPS_DEMO/schemas/MODEL_REGISTRY/model/CUSTOMER_REVENUE_MODEL/version/V1/monitors/MM_V1/dashboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35973caf-79c3-4378-a258-f7ace897cba9",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "cell58"
   },
   "outputs": [],
   "source": [
    "with st.expander('**Need help deciding for the right metric?**', expanded=False):\n",
    "    text = \"\"\"### **Overview of Feature Drift Metrics:**\n",
    "\n",
    "|                      | **Jensen-Shannon Distance** | **Wasserstein Distance** | **Difference of Means** |\n",
    "|-----------------------------|----------------|--------------------------|-------------------------|\n",
    "| **What It Measures**        | Difference in probability distributions | Amount of movement needed to align two distributions | Simple difference between means of two distributions |\n",
    "| **Intuition**               | Measures how **different** two distributions are (based on KL divergence, but smoothed and symmetric). | Measures the **work needed** to \"move\" one distribution to match the other. | Measures the shift in the **central tendency** of the feature values. |\n",
    "| **Range**                   | 0 to 1 (bounded) | 0 to âˆž (can grow indefinitely) | -âˆž to âˆž (unbounded) |\n",
    "| **Interpretability**        | 0 = identical, 1 = completely different | Larger values mean greater distribution shift | Positive = mean has increased, Negative = mean has decreased |\n",
    "| **Computational Complexity** | Faster, works well with discrete values | Slower, requires solving an optimization problem | Very fast (simple arithmetic) |\n",
    "| **Small shifts in values**  | May not detect it well if probability distributions overlap a lot. | Captures even small shifts because it looks at the actual distance between values. | Only detects shifts in the mean, not overall distribution changes. |\n",
    "| **Major changes in shape**  | Captures well if distributions change significantly. | Captures well if mass shifts significantly. | âŒ No, only captures mean changes. |\n",
    "| **Outliers or extreme shifts** | May be less sensitive if distributions overlap in many places. | More sensitive because it considers the actual movement of values. | Very sensitive to outliers (mean can shift significantly). |\n",
    "| **Best for categorical distributions** (e.g., customer segments) | âœ… Yes | âŒ No | âŒ No |\n",
    "| **Best for continuous features** (e.g., age, income) | âŒ No | âœ… Yes | âœ… Yes |\n",
    "| **Best for detecting gradual numerical shifts** | âŒ No | âœ… Yes | âœ… Yes, but only if the mean is shifting. |\n",
    "| **Best for interpretable (bounded 0-1) metric** | âœ… Yes | âŒ No | âŒ No |\"\"\"\n",
    "    st.markdown(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace518d-69fb-4eeb-ba99-ef17a5707655",
   "metadata": {
    "collapsed": false,
    "name": "cell36"
   },
   "source": [
    "### Query the model monitor\n",
    "With the built-in functions, querying metrics from the model monitor becomes effortless, allowing for further analysis and visualization.\n",
    "Additionally, this notebook includes a small helper for the model registry, enabling you to quickly navigate through your registered models, visualize their metrics, and compare multiple models in a single graph.\n",
    "\n",
    "Moreover, the outputs from these model registry functions can be leveraged to create alerts and trigger automated tasks. Example use cases include:\n",
    "* Sending an email notification to your ML engineer if a model's performance drops below a predefined threshold.\n",
    "* Initiating an automated retraining of a model with fresh data using [Snowflake Tasks](https://docs.snowflake.com/en/user-guide/tasks-intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae94833-4b55-463d-877c-8425010dae1f",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "session.table_function(\n",
    "    \"MODEL_MONITOR_DRIFT_METRIC\",\n",
    "    lit('MM_V1'),\n",
    "    lit('WASSERSTEIN'),\n",
    "    lit('TOTAL_REVENUE_IN_SHOP_PAST_1_MONTHS'),\n",
    "    lit('1 day'),\n",
    "    lit('2024-01-01'),\n",
    "    lit('2024-12-31')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "id": "a1392667-4209-483c-bbf4-ea8cc3a2cb93",
   "metadata": {
    "language": "python",
    "name": "cell61"
   },
   "outputs": [],
   "source": "model_registry_helper = ModelRegistryHelper(session, reg)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1b727af-068b-43a3-94e3-e4f277b61127",
   "metadata": {
    "language": "python",
    "name": "cell70"
   },
   "outputs": [],
   "source": "model_registry_helper.plot_model_performance()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6a7327c-9ebf-455b-b1c7-74ca9c416592",
   "metadata": {
    "collapsed": false,
    "name": "cell72"
   },
   "source": "### Why is the new model performing better?\nLet's ask CortexPilot what changed.\n\nThe bar chart displays the overall revenue per month, categorized by transaction channel (Online and In-Shop). It shows a notable increase in online transactions starting in June."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c579eb-0cf3-4fce-bcf3-110bc19ccc9b",
   "metadata": {
    "language": "python",
    "name": "cell59"
   },
   "outputs": [],
   "source": "my_pilot.f_cortex_helper_visualize_query(\n    transactions_df, \n    'What was the overall revenue per channel and month? Use a stacked bar plot and use YY-Monthname for the x-axis. Make sure the x-axis is ordered by month.'\n)"
  },
  {
   "cell_type": "markdown",
   "id": "d2686a6c-4210-45f7-ab2d-32fb61a9d11f",
   "metadata": {
    "collapsed": false,
    "name": "NEW_MODEL_1"
   },
   "source": [
    "## Train a new Model Version  \n",
    "\n",
    "Since **user behavior has changed**, we will train a **new version of our model** using fresh data.  \n",
    "\n",
    "To streamline this process, I have encapsulated the entire training workflow into the helper function `train_new_model()`, which automates the following steps:  \n",
    "\n",
    "- **Creates the spine DataFrame**, including the target variable.  \n",
    "- **Retrieves features** from the Feature Store.  \n",
    "- **Creates a Snowflake Dataset** from the training data (ensuring reproducibility with a snapshot).  \n",
    "- **Trains a new XGBoost model**.  \n",
    "- **Registers the model** in the Snowflake Model Registry.  \n",
    "- **Sets up a new model monitor** to track performance and drift.  \n",
    "- **Compares model performance** against the existing production model.  \n",
    "- **Deploys the new model** if it outperforms the current one by assigning it the **\"PRODUCTION\"** alias.  \n",
    "\n",
    "Since the training data includes **June, July, and August 2024** (covering training data up to **Septemer 1st, 2024**, and looking back three months), the model should recognize that **ONLINE transactions** have become a major driver of customer revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e2112-fb57-4a33-aa37-c7e972ecc363",
   "metadata": {
    "language": "python",
    "name": "MODELTRAINER_CODE",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import logging\nfrom opentelemetry import trace\n\nclass ModelTrainer():\n    def __init__(self, session):\n        self.session = session\n        self.registry = Registry(\n            session=session, \n            database_name='SIMPLE_MLOPS_DEMO',\n            schema_name='MODEL_REGISTRY', \n            options={'enable_monitoring': True},\n        )\n        self.fs = FeatureStore(\n            session=session, \n            database='SIMPLE_MLOPS_DEMO', \n            name='FEATURE_STORE', \n            default_warehouse=session.get_current_warehouse(),\n            creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n        )\n        self.logger = logging.getLogger(\"logger.ModelTrainer\")\n        self.tracer = trace.get_tracer(\"tracer.ModelTrainer\")\n\n    def train_new_model(self, feature_views: dict, feature_cutoff_date: str, target_start_date: str, target_end_date: str, model_version: str):\n        train_df, test_df, feature_columns = self.prepare_data(feature_views, feature_cutoff_date, target_start_date, target_end_date, model_version)\n        model = self.train(train_df, feature_columns)\n        mape, predictions = self.evaluate_model(model, test_df)\n        registered_model = self.register_new_model(model, model_version, train_df, feature_columns, feature_cutoff_date, mape)\n        self.create_model_monitor(registered_model, model_version, predictions)\n        self.evaluate_against_production_model(registered_model, test_df, mape)\n\n    def prepare_data(self, feature_views: dict, feature_cutoff_date: str, target_start_date: str, target_end_date: str, model_version: str):\n        with self.tracer.start_as_current_span(\"Data Preparation\"):\n            feature_views = [self.fs.get_feature_view(fv,feature_views[fv]) for fv in feature_views]\n            target_df = self.session.table('SIMPLE_MLOPS_DEMO.RETAIL_DATA.TRANSACTIONS')\n            target_df = (\n                target_df.filter(col('DATE').between(target_start_date,target_end_date))\n                .group_by('CUSTOMER_ID')\n                .agg(F.sum('TRANSACTION_AMOUNT').as_('NEXT_MONTH_REVENUE'))\n                .with_column('FEATURE_CUTOFF_DATE', F.to_date(lit(feature_cutoff_date)))\n            )\n            \n            customers_df = self.session.table('SIMPLE_MLOPS_DEMO.RETAIL_DATA.CUSTOMERS').select('CUSTOMER_ID').distinct()\n            spine_df = target_df.join(customers_df, on=['CUSTOMER_ID'], how='outer')\n            spine_df = spine_df.fillna(0, subset='NEXT_MONTH_REVENUE')\n    \n            train_dataset = self.fs.generate_dataset(\n                name=\"SIMPLE_MLOPS_DEMO.FEATURE_STORE.NEXT_MONTH_REVENUE_DATASET\",\n                spine_df=spine_df,\n                features=feature_views,\n                version=model_version,\n                spine_timestamp_col=\"FEATURE_CUTOFF_DATE\",\n                spine_label_cols=[\"NEXT_MONTH_REVENUE\"],\n                include_feature_view_timestamp_col=False,\n                desc=f\"Training dataset from {feature_cutoff_date}\"\n            )\n            \n            df = train_dataset.read.to_snowpark_dataframe()\n            train_df, test_df = df.random_split(weights=[0.9, 0.1], seed=0)\n            feature_columns = train_df.drop(['CUSTOMER_ID', 'FEATURE_CUTOFF_DATE', 'NEXT_MONTH_REVENUE']).columns\n            self.logger.info('Training dataset created.')\n            return  train_df, test_df, feature_columns\n        \n    def train(self, train_df, feature_columns):\n        with self.tracer.start_as_current_span(\"Model Fitting\"):\n            model = XGBRegressor(\n                input_cols=feature_columns,\n                label_cols=['NEXT_MONTH_REVENUE'],\n                output_cols=['NEXT_MONTH_REVENUE_PREDICTION'],\n                n_estimators=100,\n                learning_rate=0.05,\n                random_state=0\n            )\n            model = model.fit(train_df)\n            feature_importance = dict(zip(feature_columns, xgb_model.to_xgboost().feature_importances_))\n            telemetry.add_event(\"model_training\", {\"feature_importance\": feature_importance})\n            self.logger.info('Successfully trained a new model.')\n            return model\n\n    def evaluate_model(self, model, test_df):\n        with self.tracer.start_as_current_span(\"Model Evaluation\"):\n            predictions = model.predict(test_df)\n            mape = mean_absolute_percentage_error(\n                df=predictions, \n                y_true_col_names=\"NEXT_MONTH_REVENUE\", \n                y_pred_col_names=\"NEXT_MONTH_REVENUE_PREDICTION\"\n            )\n            telemetry.add_event(\"model_evaluation\", {\"metric\": \"mape\", \"value\": mape})\n            self.logger.info(f'New model has a MAPE of {mape}.')\n            return mape, predictions\n\n    def register_new_model(self, model, model_version, train_df, feature_columns, feature_cutoff_date, mape):\n        with self.tracer.start_as_current_span(\"Model Registration\"):\n            registered_model = self.registry.log_model(\n                model,\n                model_name=\"CUSTOMER_REVENUE_MODEL\",\n                version_name=model_version,\n                metrics={\n                    'MAPE': mape, \n                    'TRAINING_DATA': {'FEATURE_CUTOFF_DATE': feature_cutoff_date}\n                },\n                comment=\"Model trained using XGBoost to predict revenue per customer for next month.\",\n                conda_dependencies=['xgboost'],\n                sample_input_data=train_df.select(feature_columns).limit(10),\n                options={\"relax_version\": False, \"enable_explainability\": True}\n            )\n            self.logger.info(f'Registered new model with version {model_version} in model registry.')\n            return registered_model\n\n    def create_model_monitor(self, registered_model, model_version, predictions):\n        with self.tracer.start_as_current_span(\"Model Monitor Creation\"):\n            predictions.write.save_as_table(f'SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_BASELINE_{model_version}', mode='overwrite')\n            predictions.write.save_as_table(f'SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_SOURCE_{model_version}', mode='overwrite')\n            \n            source_config = ModelMonitorSourceConfig(\n                source=f'SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_SOURCE_{model_version}',\n                baseline=f'SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_REVENUE_BASELINE_{model_version}',\n                timestamp_column='FEATURE_CUTOFF_DATE',\n                id_columns=['CUSTOMER_ID'],\n                prediction_score_columns=['NEXT_MONTH_REVENUE_PREDICTION'],\n                actual_score_columns=['NEXT_MONTH_REVENUE'],\n            )\n            \n            monitor_config = ModelMonitorConfig(\n                model_version=registered_model,\n                model_function_name='predict',\n                background_compute_warehouse_name='COMPUTE_WH',\n                refresh_interval='1 minute',\n                aggregation_window='1 day'\n            )\n            \n            model_monitor = self.registry.add_monitor(\n                name=f'SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.MM_{model_version}',\n                source_config=source_config,\n                model_monitor_config=monitor_config\n            )\n\n    def evaluate_against_production_model(self, registered_model, test_df, mape):\n        with self.tracer.start_as_current_span(\"Model Deployment\"):\n            production_model = self.registry.get_model('CUSTOMER_REVENUE_MODEL').version('PRODUCTION')\n            production_model_predictions = production_model.run(test_df, function_name='PREDICT')\n            production_model_mape = mean_absolute_percentage_error(\n                df=production_model_predictions, \n                y_true_col_names=\"NEXT_MONTH_REVENUE\", \n                y_pred_col_names=\"NEXT_MONTH_REVENUE_PREDICTION\"\n            )\n            \n            if mape < production_model_mape:\n                self.logger.info(f\"New model has a lower MAPE compared to current production model.\")\n                self.logger.info(f\"New model will be put into production by setting its alias to PRODUCTION.\")\n                \n                # Update model aliases:\n                production_model.unset_alias('PRODUCTION')\n                production_model.set_alias('DEPRECATED')\n                registered_model.set_alias('PRODUCTION')\n            else:\n                self.logger.info(f\"Existing production model has a lower MAPE compared to the developed model.\")\n                self.logger.info(f\"New model is not automatically set into production.\")"
  },
  {
   "cell_type": "markdown",
   "id": "47b39cfd-e4d8-4430-b62c-cad996396591",
   "metadata": {
    "collapsed": false,
    "name": "cell73"
   },
   "source": [
    "### Deploy the training pipeline\n",
    "Our pipeline is fairly simple but for demo purposes we will create a Directed-Acyclic-Graph (DAG) for it.  \n",
    "This DAG consists of two Stored Procedures which capsulate logic for each step and allow detailed monitoring.  \n",
    "\n",
    "1. Training a new model with fresh data\n",
    "2. Sending Notifications\n",
    "\n",
    "By registering the functions as Stored Procedures, they become available outside of this notebook for everybody with the right privileges.\n",
    "Your co-developers can then easily integrate your work in their pipelines even if they are developing in other IDEs or even languages (e.g. SQL).\n",
    "\n",
    "Last but not least, Snowflake is capturing logs, metrics and traces for your Stored Procedures, UDFs, etc. automatically in [Event Tables](https://docs.snowflake.com/en/developer-guide/logging-tracing/event-table-setting-up).  \n",
    "**Note:** You need to [enable telemetry collection](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging-tracing-enabling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b851b4-ec0d-4efc-aa13-cdfd81ef8fd0",
   "metadata": {
    "language": "python",
    "name": "cell60"
   },
   "outputs": [],
   "source": "@sproc(\n    name='TRAIN_CUSTOMER_REVENUE_MODEL',\n    is_permanent=True,\n    replace=True,\n    stage_location='SIMPLE_MLOPS_DEMO.PUBLIC.PIPELINES',\n    packages=['snowflake-snowpark-python','snowflake-ml-python==1.7.4','snowflake-telemetry-python'],\n    imports=['@SIMPLE_MLOPS_DEMO.PUBLIC.GITHUB_REPOSITORY_SNOWFLAKE_SIMPLE_MLOPS/branches/main/src/demo_extras/model_trainer.py'],\n    execute_as='caller'\n)\ndef train_new_model(session: Session, feature_views: dict, feature_cutoff_date: str, target_start_date: str, target_end_date: str, model_version: str) -> str:\n    from model_trainer import ModelTrainer\n    logger = logging.getLogger(\"logger.ModelTrainer\")\n    tracer = trace.get_tracer(\"tracer.ModelTrainer\")\n    logger.info('Starting model training.')\n    with tracer.start_as_current_span(\"XGBoost Pipeline\"):\n        model_trainer = ModelTrainer(session)\n        model_trainer.train_new_model(feature_views, feature_cutoff_date, target_start_date, target_end_date, model_version)\n    logger.info('Model training finished.')\n    return 'Successfully trained and registered a new model.'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab36dd-614d-418e-a1cb-6f43fa335ee6",
   "metadata": {
    "language": "python",
    "name": "cell68"
   },
   "outputs": [],
   "source": "feature_views = {'IN_SHOP_REVENUE_FEATURES':'V1', 'ONLINE_REVENUE_FEATURES':'V1'}\nfeature_cutoff_date = '2024-09-01'\ntarget_start_date = '2024-09-02'\ntarget_end_date = '2024-10-01'\nmodel_version = 'V2'\n\ntrain_new_model(session, feature_views, feature_cutoff_date, target_start_date, target_end_date, model_version)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2214567-96c6-4ccc-aa98-0ffe72de9014",
   "metadata": {
    "language": "python",
    "name": "cell69"
   },
   "outputs": [],
   "source": [
    "#model_trainer = ModelTrainer(session)\n",
    "#\n",
    "#feature_views = {'IN_SHOP_REVENUE_FEATURES':'V1', 'ONLINE_REVENUE_FEATURES':'V1'}\n",
    "#feature_cutoff_date = '2024-09-01'\n",
    "#target_start_date = '2024-09-02'\n",
    "#target_end_date = '2024-10-01'\n",
    "#model_version = 'V2'\n",
    "#\n",
    "#model_trainer.train_new_model(feature_views, feature_cutoff_date, target_start_date, target_end_date, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75783fe-e8ed-435f-ab39-8d592166576d",
   "metadata": {
    "collapsed": false,
    "name": "NEW_MODEL_3"
   },
   "source": [
    "### Simulate Model performance for Model Version V2 until 2025-01-31\n",
    "Once again, we are simulating **model performance** based on customer transactions up to **February 2025**.  \n",
    "Make sure to check the **model monitor** to evaluate whether the new model version trained on more recent data performs better.  \n",
    "Additionally, analyze the **feature drift**, where youâ€™ll notice that the trend for the **V2 model** is much more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe2c80-0c46-4f7f-8f1d-292226bb7469",
   "metadata": {
    "language": "python",
    "name": "cell37"
   },
   "outputs": [],
   "source": [
    "model = reg.get_model('CUSTOMER_REVENUE_MODEL').version('V2')\n",
    "start_date = '2024-10-01'\n",
    "end_date = '2025-01-01'\n",
    "demo_flow.simulate_model_performance(model, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a3938-eccc-4fcf-8fb4-0e26d9848dd1",
   "metadata": {
    "language": "python",
    "name": "cell38"
   },
   "outputs": [],
   "source": [
    "model_registry_helper.plot_model_performance(update_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a76de0-74ac-4f25-84f3-4717b33c51fb",
   "metadata": {
    "collapsed": false,
    "name": "cell56"
   },
   "source": "### Comparing the two Model Versions\nWe have already observed that the new model provides **significantly better predictions** for future customer revenue. However, we want to gain deeper insights into **why** this improvement occurred.  \n\nTo analyze this, we are generating the SHAP Summary Plot for both models for the latest data. This reveals that the new model recognizes a **much stronger influence** of past **ONLINE transactions** on future customer revenue.  "
  },
  {
   "cell_type": "code",
   "id": "359172b6-0c73-4998-9fd0-bd04f87c9f9e",
   "metadata": {
    "language": "python",
    "name": "cell76"
   },
   "outputs": [],
   "source": "model_registry_helper.update_registry_data()\n\nshap_exp1 = model_registry_helper.get_model_explanations(\n    reg.get_model('CUSTOMER_REVENUE_MODEL').version('V1'), feature_columns=feature_columns, feature_cutoff_date='2025-01-01'\n)\n\nshap_exp2 = model_registry_helper.get_model_explanations(\n    reg.get_model('CUSTOMER_REVENUE_MODEL').version('V2'), feature_columns=feature_columns, feature_cutoff_date='2025-01-01'\n)\n\ncol1, col2 = st.columns(2)\nwith col1:\n    shap.summary_plot(shap_exp1)\nwith col2:\n    shap.summary_plot(shap_exp2)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6177a3c1-8d98-4900-83ea-f0ec4a910b20",
   "metadata": {
    "collapsed": false,
    "name": "cell25"
   },
   "source": [
    "## ML Lineage\n",
    "Even though you may not have noticed, youâ€™ve been capturing **lineage information** throughout the development of your machine learning pipeline.  \n",
    "\n",
    "You can retrieve this information using the built-in function `lineage.trace()` for further analysis.  \n",
    "For example, you can use this data to **visualize the lineage directly in the notebook**.  \n",
    "\n",
    "Additionally, Snowflake provides a **more user-friendly and interactive UI** that allows you to explore and monitor your machine learning pipeline:  \n",
    "![text](https://github.com/michaelgorkow/snowflake_simple_mlops/blob/main/resources/ml_lineage3.png?raw=true)\n",
    "\n",
    "As shown, the lineage captures a **comprehensive view** of your pipeline, tracking data transformations and dependencies from the **source tables**, through the **feature view**, the **training dataset**, and ultimately the **registered model** in the Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775030b5-6034-4827-a44f-60fc2ec01392",
   "metadata": {
    "language": "python",
    "name": "cell57"
   },
   "outputs": [],
   "source": [
    "get_snowsight_url(session, 'Link to Lineage View', '#/data/databases/SIMPLE_MLOPS_DEMO/schemas/MODEL_REGISTRY/model/CUSTOMER_REVENUE_MODEL/version/V2/lineage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fab3ee-19e7-4a34-a86a-cd09efec9065",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell45"
   },
   "outputs": [],
   "source": [
    "trace = session.lineage.trace(\n",
    "    object_name='SIMPLE_MLOPS_DEMO.MODEL_REGISTRY.CUSTOMER_REVENUE_MODEL',\n",
    "    object_version='V2',\n",
    "    object_domain='model',\n",
    "    direction='both',\n",
    "    distance=2\n",
    ")\n",
    "trace.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924a8b0-75ca-46b3-bd57-c3edd59a16a4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "lineage_helper = LineageHelper()\n",
    "lineage_helper.visualize_lineage(trace.to_pandas(), short_names=True)"
   ]
  }
 ]
}